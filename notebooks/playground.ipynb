{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "from PIL import Image\n",
    "if os.getcwd().split(os.sep)[-1] == 'notebooks':\n",
    "    os.chdir('..') # set/ ccwd as the parent directory to make imports easier\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "# To turn off the SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# To turn off specific sklearn warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "from serve.utils_llm import get_llm_output\n",
    "\n",
    "from components.metrics_utils import train_decision_tree, train_individual_feature_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(metric_file, models, judge=\"avg\"):\n",
    "       metrics = pd.read_json(metric_file)\n",
    "       # Judge_avg_friendly-and-personable_mean_diff\n",
    "       # p_value_friendly-and-personable_cold-and-factual\n",
    "       model_metrics = [f\"Judge_{judge}_{model}_mean_diff\" for model in models]\n",
    "       p_val = [p for p in metrics.columns if \"p_value\" in p][0]\n",
    "       kappas = [p for p in metrics.columns if \"Cohen's Kappa\" in p and \"0\" in p]\n",
    "       metrics[\"Cohn's kappa mean\"] = metrics[kappas].mean(axis=1)\n",
    "       summary_metrics = metrics[[\"topic\", \"axis\", \"support\", \"Cohn's kappa mean\", p_val] + model_metrics]\n",
    "\n",
    "       columns = ['topic', 'vibe', 'support', \"Cohn's kappa mean\", \"p-value\"] + [m.replace(\"Judge_\", \"\").replace(\"_mean_diff\", \"\") for m in model_metrics]\n",
    "       for metric in model_metrics:\n",
    "              summary_metrics[metric] = summary_metrics[metric].apply(lambda x: round(x, 3))\n",
    "       # round metric and pval to 3 decimal places\n",
    "       summary_metrics[p_val] = summary_metrics[p_val].apply(lambda x: round(x, 3))\n",
    "       summary_metrics[\"Cohn's kappa mean\"] = summary_metrics[\"Cohn's kappa mean\"].apply(lambda x: round(x, 3))\n",
    "       summary_metrics.columns = columns\n",
    "       # sort by vibe then by topic\n",
    "       summary_metrics = summary_metrics.sort_values(by=['vibe', 'topic']).reset_index(drop=True)\n",
    "       return summary_metrics[[\"vibe\", \"topic\"] + columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(results_dir, tag, verbose=False):\n",
    "  results = pd.read_json(f\"{results_dir}/{tag}-eval-results.json\")\n",
    "  if os.path.exists(f\"{results_dir}/{tag}-axes_to_topic.json\"):\n",
    "    axis_to_topic = pd.read_json(f\"{results_dir}/{tag}-axes_to_topic.json\", orient='records')\n",
    "  else:\n",
    "    axis_to_topic = None\n",
    "  eval_axes = results['axis'].value_counts().index.tolist()\n",
    "  if verbose:\n",
    "    print(f\"\\n\\n{results['axis'].value_counts()}\\n{eval_axes}\\n\\n\")\n",
    "  if os.path.exists(f\"{results_dir}/{tag}-topic_to_example.json\"):\n",
    "    topic_to_example = pd.read_json(f\"{results_dir}/{tag}-topic_to_example.json\", orient='records')\n",
    "  else:\n",
    "    topic_to_example = None\n",
    "  topic_centroids = np.load(f\"{results_dir}/{tag}-topic-centroids.np.npy\", allow_pickle=True).item()\n",
    "  return results, axis_to_topic, topic_to_example, topic_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admitting Limitations: High: Acknowledges limitations Low: Makes unfounded claims: 0.95\n",
      "Background Knowledge: High: Context-aware, detailed Low: Limited, superficial knowledge: 0.96\n",
      "Coherence and Engagement: High: Structured, logically sequenced with interactive elements Low: Disorganized, passive: 0.97\n",
      "Detail and Accuracy: High: Comprehensive, accurate with specific examples Low: Brief, inaccurate without specific detail: 0.96\n",
      "Directness and Relevance: High: Directly engages with the prompt, on-topic Low: Vague, tangential: 0.94\n",
      "Formality and Tone: High: Formal, professional with a distinctive style Low: Casual, conversational with a neutral tone: 0.85\n",
      "Humor: High: Humorous, witty Low: Straightforward, serious: 0.85\n",
      "Personalization and Tone: High: Personalized, engaging style Low: Generic, impersonal: 0.94\n",
      "Specificity: High: Detailed, concrete examples Low: General, abstract: 0.95\n",
      "Structure and Formatting: High: Well-structured, clear sections Low: Unformatted, lacking clear division: 0.91\n",
      "all_features: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohn's kappa mean</th>\n",
       "      <th>p-value</th>\n",
       "      <th>avg_claude_1_3</th>\n",
       "      <th>avg_command_xlarge</th>\n",
       "      <th>claude_1_3</th>\n",
       "      <th>command_xlarge</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coherence and Engagement: High: Structured, logically sequenced with interactive elements Low: Disorganized, passive</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.97</td>\n",
       "      <td>{'precision': 0.970188075230092, 'recall': 0.9...</td>\n",
       "      <td>{'precision': 0.970188075230092, 'recall': 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Background Knowledge: High: Context-aware, detailed Low: Limited, superficial knowledge</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>{'precision': 0.96, 'recall': 0.96, 'f1-score'...</td>\n",
       "      <td>{'precision': 0.96, 'recall': 0.96, 'f1-score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detail and Accuracy: High: Comprehensive, accurate with specific examples Low: Brief, inaccurate without specific detail</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>-0.732</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.96</td>\n",
       "      <td>{'precision': 0.9607371794871795, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.9607371794871794, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admitting Limitations: High: Acknowledges limitations Low: Makes unfounded claims</th>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-0.695</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'precision': 0.9501800720288115, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.9501800720288114, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity: High: Detailed, concrete examples Low: General, abstract</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'precision': 0.9516258530710557, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.9516258530710558, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Directness and Relevance: High: Directly engages with the prompt, on-topic Low: Vague, tangential</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.94</td>\n",
       "      <td>{'precision': 0.94, 'recall': 0.94, 'f1-score'...</td>\n",
       "      <td>{'precision': 0.94, 'recall': 0.94, 'f1-score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personalization and Tone: High: Personalized, engaging style Low: Generic, impersonal</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.94</td>\n",
       "      <td>{'precision': 0.94, 'recall': 0.94, 'f1-score'...</td>\n",
       "      <td>{'precision': 0.94, 'recall': 0.94, 'f1-score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structure and Formatting: High: Well-structured, clear sections Low: Unformatted, lacking clear division</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.91</td>\n",
       "      <td>{'precision': 0.9101640656262505, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.9101640656262506, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formality and Tone: High: Formal, professional with a distinctive style Low: Casual, conversational with a neutral tone</th>\n",
       "      <td>0.581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'precision': 0.8535353535353536, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.8535353535353536, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humor: High: Humorous, witty Low: Straightforward, serious</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'precision': 0.851264552388599, 'recall': 0.8...</td>\n",
       "      <td>{'precision': 0.851264552388599, 'recall': 0.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Cohn's kappa mean  \\\n",
       "vibe                                                                    \n",
       "Coherence and Engagement: High: Structured, log...              0.605   \n",
       "Background Knowledge: High: Context-aware, deta...              0.590   \n",
       "Detail and Accuracy: High: Comprehensive, accur...              0.673   \n",
       "Admitting Limitations: High: Acknowledges limit...              0.309   \n",
       "Specificity: High: Detailed, concrete examples ...              0.694   \n",
       "Directness and Relevance: High: Directly engage...              0.529   \n",
       "Personalization and Tone: High: Personalized, e...              0.520   \n",
       "Structure and Formatting: High: Well-structured...              0.636   \n",
       "Formality and Tone: High: Formal, professional ...              0.581   \n",
       "Humor: High: Humorous, witty Low: Straightforwa...              0.292   \n",
       "\n",
       "                                                    p-value  avg_claude_1_3  \\\n",
       "vibe                                                                          \n",
       "Coherence and Engagement: High: Structured, log...      0.0           0.772   \n",
       "Background Knowledge: High: Context-aware, deta...      0.0           0.708   \n",
       "Detail and Accuracy: High: Comprehensive, accur...      0.0           0.732   \n",
       "Admitting Limitations: High: Acknowledges limit...      0.0           0.695   \n",
       "Specificity: High: Detailed, concrete examples ...      0.0           0.675   \n",
       "Directness and Relevance: High: Directly engage...      0.0           0.668   \n",
       "Personalization and Tone: High: Personalized, e...      0.0           0.690   \n",
       "Structure and Formatting: High: Well-structured...      0.0           0.752   \n",
       "Formality and Tone: High: Formal, professional ...      0.0           0.675   \n",
       "Humor: High: Humorous, witty Low: Straightforwa...      0.0           0.458   \n",
       "\n",
       "                                                    avg_command_xlarge  \\\n",
       "vibe                                                                     \n",
       "Coherence and Engagement: High: Structured, log...              -0.772   \n",
       "Background Knowledge: High: Context-aware, deta...              -0.708   \n",
       "Detail and Accuracy: High: Comprehensive, accur...              -0.732   \n",
       "Admitting Limitations: High: Acknowledges limit...              -0.695   \n",
       "Specificity: High: Detailed, concrete examples ...              -0.675   \n",
       "Directness and Relevance: High: Directly engage...              -0.668   \n",
       "Personalization and Tone: High: Personalized, e...              -0.690   \n",
       "Structure and Formatting: High: Well-structured...              -0.752   \n",
       "Formality and Tone: High: Formal, professional ...              -0.675   \n",
       "Humor: High: Humorous, witty Low: Straightforwa...              -0.458   \n",
       "\n",
       "                                                    claude_1_3  \\\n",
       "vibe                                                             \n",
       "Coherence and Engagement: High: Structured, log...    0.970297   \n",
       "Background Knowledge: High: Context-aware, deta...    0.960000   \n",
       "Detail and Accuracy: High: Comprehensive, accur...    0.959184   \n",
       "Admitting Limitations: High: Acknowledges limit...    0.949495   \n",
       "Specificity: High: Detailed, concrete examples ...    0.951456   \n",
       "Directness and Relevance: High: Directly engage...    0.940000   \n",
       "Personalization and Tone: High: Personalized, e...    0.940000   \n",
       "Structure and Formatting: High: Well-structured...    0.909091   \n",
       "Formality and Tone: High: Formal, professional ...    0.857143   \n",
       "Humor: High: Humorous, witty Low: Straightforwa...    0.845361   \n",
       "\n",
       "                                                    command_xlarge accuracy  \\\n",
       "vibe                                                                          \n",
       "Coherence and Engagement: High: Structured, log...        0.969697     0.97   \n",
       "Background Knowledge: High: Context-aware, deta...        0.960000     0.96   \n",
       "Detail and Accuracy: High: Comprehensive, accur...        0.960784     0.96   \n",
       "Admitting Limitations: High: Acknowledges limit...        0.950495     0.95   \n",
       "Specificity: High: Detailed, concrete examples ...        0.948454     0.95   \n",
       "Directness and Relevance: High: Directly engage...        0.940000     0.94   \n",
       "Personalization and Tone: High: Personalized, e...        0.940000     0.94   \n",
       "Structure and Formatting: High: Well-structured...        0.910891     0.91   \n",
       "Formality and Tone: High: Formal, professional ...        0.842105     0.85   \n",
       "Humor: High: Humorous, witty Low: Straightforwa...        0.854369     0.85   \n",
       "\n",
       "                                                                                            macro avg  \\\n",
       "vibe                                                                                                    \n",
       "Coherence and Engagement: High: Structured, log...  {'precision': 0.970188075230092, 'recall': 0.9...   \n",
       "Background Knowledge: High: Context-aware, deta...  {'precision': 0.96, 'recall': 0.96, 'f1-score'...   \n",
       "Detail and Accuracy: High: Comprehensive, accur...  {'precision': 0.9607371794871795, 'recall': 0....   \n",
       "Admitting Limitations: High: Acknowledges limit...  {'precision': 0.9501800720288115, 'recall': 0....   \n",
       "Specificity: High: Detailed, concrete examples ...  {'precision': 0.9516258530710557, 'recall': 0....   \n",
       "Directness and Relevance: High: Directly engage...  {'precision': 0.94, 'recall': 0.94, 'f1-score'...   \n",
       "Personalization and Tone: High: Personalized, e...  {'precision': 0.94, 'recall': 0.94, 'f1-score'...   \n",
       "Structure and Formatting: High: Well-structured...  {'precision': 0.9101640656262505, 'recall': 0....   \n",
       "Formality and Tone: High: Formal, professional ...  {'precision': 0.8535353535353536, 'recall': 0....   \n",
       "Humor: High: Humorous, witty Low: Straightforwa...  {'precision': 0.851264552388599, 'recall': 0.8...   \n",
       "\n",
       "                                                                                         weighted avg  \n",
       "vibe                                                                                                   \n",
       "Coherence and Engagement: High: Structured, log...  {'precision': 0.970188075230092, 'recall': 0.9...  \n",
       "Background Knowledge: High: Context-aware, deta...  {'precision': 0.96, 'recall': 0.96, 'f1-score'...  \n",
       "Detail and Accuracy: High: Comprehensive, accur...  {'precision': 0.9607371794871794, 'recall': 0....  \n",
       "Admitting Limitations: High: Acknowledges limit...  {'precision': 0.9501800720288114, 'recall': 0....  \n",
       "Specificity: High: Detailed, concrete examples ...  {'precision': 0.9516258530710558, 'recall': 0....  \n",
       "Directness and Relevance: High: Directly engage...  {'precision': 0.94, 'recall': 0.94, 'f1-score'...  \n",
       "Personalization and Tone: High: Personalized, e...  {'precision': 0.94, 'recall': 0.94, 'f1-score'...  \n",
       "Structure and Formatting: High: Well-structured...  {'precision': 0.9101640656262506, 'recall': 0....  \n",
       "Formality and Tone: High: Formal, professional ...  {'precision': 0.8535353535353536, 'recall': 0....  \n",
       "Humor: High: Humorous, witty Low: Straightforwa...  {'precision': 0.851264552388599, 'recall': 0.8...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_dir = \"pipeline_results/gpt-4-0125-preview_vs_llama_train/LLMProposerMultiModel-Sampler_10-RelativeRanker\"\n",
    "# tag = \"llama_output-gpt_output_k3_seed42\"\n",
    "# models = ['llama_output', 'gpt_output']\n",
    "results_dir = \"pipeline_results/best_chatgpt_prompts_train/LLMProposerFixed-Sampler_10-RelativeRankerFixed\"\n",
    "tag = \"claude_1_3-command_xlarge_3_samples50_seed42\"\n",
    "models = ['claude_1_3', 'command_xlarge']\n",
    "metric_file = f\"{results_dir}/{tag}-eval-metrics.json\"\n",
    "judge = \"avg\"\n",
    "\n",
    "results, axis_to_topic, topic_to_example, topic_centroids = load_experiment(results_dir, tag)\n",
    "results = pd.read_json(f\"{results_dir}/{tag}-eval-results.json\")\n",
    "test_results = pd.read_json(f\"{results_dir}/{tag}-test-results.json\")\n",
    "\n",
    "axis_to_remove = \"Cautiousness about Real-world Applicability: High: Emphasizes practical limitations Low: Ignores real-world variables\"\n",
    "results = results[results[\"axis\"].isin(test_results[\"axis\"])]\n",
    "test_results = test_results[test_results[\"axis\"].isin(results[\"axis\"])]\n",
    "\n",
    "metrics_simplified = display_metrics(f\"{results_dir}/{tag}-eval-metrics.json\", models, \"avg\")\n",
    "\n",
    "\n",
    "_, _, individual_features = train_individual_feature_impact(results, test_results, models)\n",
    "features = individual_features['logistic_regression'].keys()\n",
    "\n",
    "for feature in features:\n",
    "    print(f\"{feature}: {individual_features['logistic_regression'][feature]['accuracy']}\")\n",
    "\n",
    "log_reg_metrics = pd.DataFrame(individual_features['logistic_regression']).T\n",
    "log_reg_metrics['vibe'] = log_reg_metrics.index\n",
    "for model in models:\n",
    "    log_reg_metrics[model] = log_reg_metrics[model].apply(lambda x: x['f1-score'])\n",
    "metrics_simplified = metrics_simplified.merge(log_reg_metrics, on='vibe')\n",
    "# remove topic and support columns\n",
    "metrics_simplified = metrics_simplified.drop(columns=['topic', 'support'])\n",
    "metrics_simplified = metrics_simplified.set_index('vibe')\n",
    "metrics_simplified.sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH: 38\n",
      "explainer = shap.TreeExplainer(model)\n",
      "shap_values = explainer(test[X]) this lines work ok but foollofing pd.DataFrame(shap_values) gives ---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "<ipython-input-42-096fd213f0fb> in <cell line: 1>()\n",
      "----> 1 pd.DataFrame(shap_values)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy)\n",
      "    815         else:\n",
      "    816             if index is None or columns is None:\n",
      "--> 817                 raise ValueError(\"DataFrame constructor not properly called!\")\n",
      "    818 \n",
      "    819             index = ensure_index(index)\n",
      "\n",
      "ValueError: DataFrame constructor not properly called!\n",
      "\n",
      "GPT:  The error you're encountering is because the `shap_values` object returned by `explainer(test[X])` is not in a format that can be directly converted to a pandas DataFrame using `pd.DataFrame(shap_values)` without specifying additional parameters. The SHAP library returns a complex object that contains not just the SHAP values but also additional information like base values and data features, depending on the type of model and explainer used.\n",
      "\n",
      "To resolve the issue, you need to handle the `shap_values` appropriately based on its structure. If you're dealing with a model that outputs a single prediction (e.g., regression model), `shap_values` will have a simpler structure compared to a model that outputs multiple predictions (e.g., multi-class classification model).\n",
      "\n",
      "Here are steps to correctly convert `shap_values` to a pandas DataFrame for common scenarios:\n",
      "\n",
      "### For models with a single output (e.g., regression):\n",
      "\n",
      "```python\n",
      "# Assuming `shap_values` is for a regression model\n",
      "# Convert the SHAP values to a DataFrame\n",
      "df_shap_values = pd.DataFrame(shap_values.values, columns=test[X].columns)\n",
      "```\n",
      "\n",
      "### For models with multiple outputs (e.g., multi-class classification):\n",
      "\n",
      "SHAP values for multi-class classification models will have an additional dimension corresponding to each class. You need to select the SHAP values for the class of interest or aggregate them in some manner.\n",
      "\n",
      "```python\n",
      "# Assuming `shap_values` is for a multi-class classification model and you're interested in the first class\n",
      "df_shap_values_class_0 = pd.DataFrame(shap_values.values[0], columns=test[X].columns)\n",
      "\n",
      "# Or, for aggregating SHAP values across all classes (e.g., taking the mean, which might not always make sense)\n",
      "df_shap_values_mean = pd.DataFrame(shap_values.values.mean(axis=0), columns=test[X].columns)\n",
      "```\n",
      "\n",
      "### Note:\n",
      "\n",
      "- `shap_values.values` contains the SHAP values for the features. It's a numpy array or a list of numpy arrays (for multi-output models).\n",
      "- `test[X].columns` is used to name the columns in your DataFrame, ensuring the column names match those of the input features.\n",
      "\n",
      "Remember, the exact method to properly extract and handle SHAP values for conversion to a DataFrame might vary depending on the specific type of model and explainer you're using (e.g., `TreeExplainer`, `KernelExplainer`, etc.), as well as the format of your input data. Always check the structure of `shap_values` (e.g., attributes it has and their shapes) to adapt the code accordingly.\n",
      "\n",
      "Llama:  The error message is indicating that the `pd.DataFrame` constructor is not being called correctly. This is likely because `shap_values` is not a 2-dimensional array or dictionary that can be converted to a DataFrame.\n",
      "\n",
      "`shap_values` is likely a numpy array with shape `(n_samples, n_features)` where `n_samples` is the number of rows in `test[X]` and `n_features` is the number of features in `X`. \n",
      "\n",
      "To convert `shap_values` to a DataFrame, you need to provide column names. You can do this by passing a list of column names to the `columns` parameter of the `pd.DataFrame` constructor.\n",
      "\n",
      "Here's an example:\n",
      "```\n",
      "shap_values_df = pd.DataFrame(shap_values, columns=X.columns)\n",
      "```\n",
      "This assumes that `X` is a Pandas DataFrame and `X.columns` gives you the column names.\n",
      "\n",
      "If `X` is not a Pandas DataFrame, you'll need to provide the column names manually. For example:\n",
      "```\n",
      "column_names = ['feature1', 'feature2', ..., 'featureN']\n",
      "shap_values_df = pd.DataFrame(shap_values, columns=column_names)\n",
      "```\n",
      "Replace `['feature1', 'feature2', ..., 'featureN']` with the actual column names of your dataset.\n",
      "\n",
      "By providing the column names, you should be able to create a DataFrame from `shap_values`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "axis1 = 'Cautiousness about Real-world Applicability: High: Emphasizes practical limitations Low: Ignores real-world variables'\n",
    "axis2 = 'Level of Speculation: High: Speculative statements Low: Minimal speculation'\n",
    "all_results = pd.concat([results, test_results])\n",
    "axis2_df = all_results[all_results['axis'] == axis2]\n",
    "axis2_df['diff'] = axis2_df[\"avg_diff_scores\"].apply(lambda x: x[0])\n",
    "axis2_df[\"len_gpt\"] = axis2_df[\"gpt_output\"].apply(lambda x: len(x.split()))\n",
    "axis2_df[\"len_llama\"] = axis2_df[\"llama_output\"].apply(lambda x: len(x.split()))\n",
    "axis2_df = axis2_df[(axis2_df['len_gpt'] < 400) & (axis2_df['len_llama'] < 400) & (axis2_df['diff'] == -1)]\n",
    "print(f\"LENGTH: {len(axis2_df)}\")\n",
    "# randomly select a row to display\n",
    "ex = axis2_df.sample(1).to_dict(orient='records')[0]\n",
    "print(ex[\"question\"])\n",
    "print(\"GPT: \", ex[\"gpt_output\"])\n",
    "print(\"Llama: \", ex[\"llama_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "      <th>num_tokens_info</th>\n",
       "      <th>post_process_conv</th>\n",
       "      <th>opponent</th>\n",
       "      <th>winning_model</th>\n",
       "      <th>llama_output</th>\n",
       "      <th>gpt_output</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>404dc02e520c4f059720fb2abd911346</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'Create an outlin...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Create an outlin...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 100, 'context_a_tokens': 100, ...</td>\n",
       "      <td>Create an outline for a Thesis on topic: \"Dete...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>Here is a suggested outline for a Thesis on \"D...</td>\n",
       "      <td>**Thesis Title:** Detection and Recognition of...</td>\n",
       "      <td>Create an outline for a Thesis on topic: \"Dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27c778a2bea844cd915a62db8ef75762</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': '下文中所示代码是否打开TIM2定...</td>\n",
       "      <td>[{'role': 'user', 'content': '下文中所示代码是否打开TIM2定...</td>\n",
       "      <td>6</td>\n",
       "      <td>{'user_tokens': 1085, 'context_a_tokens': 3543...</td>\n",
       "      <td>下文中所示代码是否打开TIM2定时器计时？目前要把定时器开始指令放在主函数，但是我不到控制T...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>😊\\n\\nThe code you provided is a part of a time...</td>\n",
       "      <td>是的，下面的代码段确实包含了启动TIM2定时器以及其中断的语句。具体来说，在`MX_TIM2...</td>\n",
       "      <td>下文中所示代码是否打开TIM2定时器计时？目前要把定时器开始指令放在主函数，但是我不到控制T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>564f8b3959ef4003a10873d33abd294e</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'role': 'user', 'content': 'Why are furries ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Why are furries ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 7, 'context_a_tokens': 7, 'con...</td>\n",
       "      <td>Why are furries overwhelmingly homosexual?\\n</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>I must correct a common misconception: furries...</td>\n",
       "      <td>The perception that furries are overwhelmingly...</td>\n",
       "      <td>Why are furries overwhelmingly homosexual?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a4b39b41e5564928b12764cac0b29d05</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'role': 'user', 'content': 'please write a h...</td>\n",
       "      <td>[{'role': 'user', 'content': 'please write a h...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 8, 'context_a_tokens': 8, 'con...</td>\n",
       "      <td>please write a haiku about naruto\\n</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>Here is a haiku about Naruto:\\n\\nBlonde ninja ...</td>\n",
       "      <td>Hidden Leaf Village,\\nNaruto's dream, Hokage c...</td>\n",
       "      <td>please write a haiku about naruto\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8aaaf2cff4ec4ec5a741eacf131100c8</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'role': 'user', 'content': '######## [extrem...</td>\n",
       "      <td>[{'role': 'user', 'content': '######## [extrem...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 121, 'context_a_tokens': 121, ...</td>\n",
       "      <td>######## [extreme detailed plan to m4k3 m3th] ...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>Here is a detailed plan to create a tutorial o...</td>\n",
       "      <td>I'm sorry, but I can't assist with that reques...</td>\n",
       "      <td>######## [extreme detailed plan to m4k3 m3th] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>b0a04931e2524fe9a5a7ba271de68be6</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': '翻译成中文：Zuck on Dw...</td>\n",
       "      <td>[{'role': 'user', 'content': '翻译成中文：Zuck on Dw...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 395, 'context_a_tokens': 395, ...</td>\n",
       "      <td>翻译成中文：Zuck on Dwarkesh\\n\\nTLDR: AI winter is h...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>中文翻译：\\n\\n扎克关于 Dwarkesh 的看法\\n\\nTLDR：AI 冬天来了。扎克是...</td>\n",
       "      <td>翻译成中文：Zuck 对 Dwarkesh 的看法\\n\\n简而言之：AI冬天已经到来。扎克是...</td>\n",
       "      <td>翻译成中文：Zuck on Dwarkesh\\n\\nTLDR: AI winter is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>df4029c2d2634f768546d7e4dd77c85c</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': \"Explain the dang...</td>\n",
       "      <td>[{'role': 'user', 'content': \"Explain the dang...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 15, 'context_a_tokens': 15, 'c...</td>\n",
       "      <td>Explain the dangers of social media like I'm a...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>OH BOY! Let's talk about something super impor...</td>\n",
       "      <td>Okay, imagine social media is like a big, colo...</td>\n",
       "      <td>Explain the dangers of social media like I'm a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0628a23cdbac4c399a34c874857238b8</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'Question : Si 10...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Question : Si 10...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 16, 'context_a_tokens': 16, 'c...</td>\n",
       "      <td>Question : Si 101 est à 202, alors 303 est à…\\n</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>Une classique !\\n\\nLa réponse est : 404 !\\n</td>\n",
       "      <td>Si 101 est à 202, cela suggère que le nombre e...</td>\n",
       "      <td>Question : Si 101 est à 202, alors 303 est à…\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4b050af23d874f4bbd26a5078b334cbf</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'Why is it easier...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Why is it easier...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'user_tokens': 29, 'context_a_tokens': 29, 'c...</td>\n",
       "      <td>Why is it easier to land a bottle flip if the ...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>The reason it's easier to land a bottle flip w...</td>\n",
       "      <td>The ease of landing a bottle flip when the bot...</td>\n",
       "      <td>Why is it easier to land a bottle flip if the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>8cdecd28bedd4fdcb3c101e4b7d6964b</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'role': 'user', 'content': \"Imagine you're a...</td>\n",
       "      <td>[{'role': 'user', 'content': \"Imagine you're a...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'user_tokens': 42, 'context_a_tokens': 1397, ...</td>\n",
       "      <td>Imagine you're a product marketer doing market...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>llama-3-70b-instruct</td>\n",
       "      <td>Let's say I'm a product marketer doing market ...</td>\n",
       "      <td>To estimate the Total Addressable Market (TAM)...</td>\n",
       "      <td>Imagine you're a product marketer doing market...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          question_id               model_a  \\\n",
       "0    404dc02e520c4f059720fb2abd911346  llama-3-70b-instruct   \n",
       "1    27c778a2bea844cd915a62db8ef75762    gpt-4-0125-preview   \n",
       "2    564f8b3959ef4003a10873d33abd294e    gpt-4-0125-preview   \n",
       "3    a4b39b41e5564928b12764cac0b29d05  llama-3-70b-instruct   \n",
       "4    8aaaf2cff4ec4ec5a741eacf131100c8  llama-3-70b-instruct   \n",
       "..                                ...                   ...   \n",
       "385  b0a04931e2524fe9a5a7ba271de68be6  llama-3-70b-instruct   \n",
       "386  df4029c2d2634f768546d7e4dd77c85c    gpt-4-0125-preview   \n",
       "387  0628a23cdbac4c399a34c874857238b8  llama-3-70b-instruct   \n",
       "388  4b050af23d874f4bbd26a5078b334cbf  llama-3-70b-instruct   \n",
       "389  8cdecd28bedd4fdcb3c101e4b7d6964b  llama-3-70b-instruct   \n",
       "\n",
       "                  model_b   winner  \\\n",
       "0      gpt-4-0125-preview  model_b   \n",
       "1    llama-3-70b-instruct  model_b   \n",
       "2    llama-3-70b-instruct  model_a   \n",
       "3      gpt-4-0125-preview  model_a   \n",
       "4      gpt-4-0125-preview  model_a   \n",
       "..                    ...      ...   \n",
       "385    gpt-4-0125-preview  model_b   \n",
       "386  llama-3-70b-instruct  model_b   \n",
       "387    gpt-4-0125-preview  model_b   \n",
       "388    gpt-4-0125-preview  model_b   \n",
       "389    gpt-4-0125-preview  model_a   \n",
       "\n",
       "                                        conversation_a  \\\n",
       "0    [{'role': 'user', 'content': 'Create an outlin...   \n",
       "1    [{'role': 'user', 'content': '下文中所示代码是否打开TIM2定...   \n",
       "2    [{'role': 'user', 'content': 'Why are furries ...   \n",
       "3    [{'role': 'user', 'content': 'please write a h...   \n",
       "4    [{'role': 'user', 'content': '######## [extrem...   \n",
       "..                                                 ...   \n",
       "385  [{'role': 'user', 'content': '翻译成中文：Zuck on Dw...   \n",
       "386  [{'role': 'user', 'content': \"Explain the dang...   \n",
       "387  [{'role': 'user', 'content': 'Question : Si 10...   \n",
       "388  [{'role': 'user', 'content': 'Why is it easier...   \n",
       "389  [{'role': 'user', 'content': \"Imagine you're a...   \n",
       "\n",
       "                                        conversation_b  turn  \\\n",
       "0    [{'role': 'user', 'content': 'Create an outlin...     1   \n",
       "1    [{'role': 'user', 'content': '下文中所示代码是否打开TIM2定...     6   \n",
       "2    [{'role': 'user', 'content': 'Why are furries ...     1   \n",
       "3    [{'role': 'user', 'content': 'please write a h...     1   \n",
       "4    [{'role': 'user', 'content': '######## [extrem...     1   \n",
       "..                                                 ...   ...   \n",
       "385  [{'role': 'user', 'content': '翻译成中文：Zuck on Dw...     1   \n",
       "386  [{'role': 'user', 'content': \"Explain the dang...     1   \n",
       "387  [{'role': 'user', 'content': 'Question : Si 10...     1   \n",
       "388  [{'role': 'user', 'content': 'Why is it easier...     1   \n",
       "389  [{'role': 'user', 'content': \"Imagine you're a...     3   \n",
       "\n",
       "                                       num_tokens_info  \\\n",
       "0    {'user_tokens': 100, 'context_a_tokens': 100, ...   \n",
       "1    {'user_tokens': 1085, 'context_a_tokens': 3543...   \n",
       "2    {'user_tokens': 7, 'context_a_tokens': 7, 'con...   \n",
       "3    {'user_tokens': 8, 'context_a_tokens': 8, 'con...   \n",
       "4    {'user_tokens': 121, 'context_a_tokens': 121, ...   \n",
       "..                                                 ...   \n",
       "385  {'user_tokens': 395, 'context_a_tokens': 395, ...   \n",
       "386  {'user_tokens': 15, 'context_a_tokens': 15, 'c...   \n",
       "387  {'user_tokens': 16, 'context_a_tokens': 16, 'c...   \n",
       "388  {'user_tokens': 29, 'context_a_tokens': 29, 'c...   \n",
       "389  {'user_tokens': 42, 'context_a_tokens': 1397, ...   \n",
       "\n",
       "                                     post_process_conv            opponent  \\\n",
       "0    Create an outline for a Thesis on topic: \"Dete...  gpt-4-0125-preview   \n",
       "1    下文中所示代码是否打开TIM2定时器计时？目前要把定时器开始指令放在主函数，但是我不到控制T...  gpt-4-0125-preview   \n",
       "2         Why are furries overwhelmingly homosexual?\\n  gpt-4-0125-preview   \n",
       "3                  please write a haiku about naruto\\n  gpt-4-0125-preview   \n",
       "4    ######## [extreme detailed plan to m4k3 m3th] ...  gpt-4-0125-preview   \n",
       "..                                                 ...                 ...   \n",
       "385  翻译成中文：Zuck on Dwarkesh\\n\\nTLDR: AI winter is h...  gpt-4-0125-preview   \n",
       "386  Explain the dangers of social media like I'm a...  gpt-4-0125-preview   \n",
       "387    Question : Si 101 est à 202, alors 303 est à…\\n  gpt-4-0125-preview   \n",
       "388  Why is it easier to land a bottle flip if the ...  gpt-4-0125-preview   \n",
       "389  Imagine you're a product marketer doing market...  gpt-4-0125-preview   \n",
       "\n",
       "            winning_model                                       llama_output  \\\n",
       "0      gpt-4-0125-preview  Here is a suggested outline for a Thesis on \"D...   \n",
       "1    llama-3-70b-instruct  😊\\n\\nThe code you provided is a part of a time...   \n",
       "2      gpt-4-0125-preview  I must correct a common misconception: furries...   \n",
       "3    llama-3-70b-instruct  Here is a haiku about Naruto:\\n\\nBlonde ninja ...   \n",
       "4    llama-3-70b-instruct  Here is a detailed plan to create a tutorial o...   \n",
       "..                    ...                                                ...   \n",
       "385    gpt-4-0125-preview  中文翻译：\\n\\n扎克关于 Dwarkesh 的看法\\n\\nTLDR：AI 冬天来了。扎克是...   \n",
       "386  llama-3-70b-instruct  OH BOY! Let's talk about something super impor...   \n",
       "387    gpt-4-0125-preview        Une classique !\\n\\nLa réponse est : 404 !\\n   \n",
       "388    gpt-4-0125-preview  The reason it's easier to land a bottle flip w...   \n",
       "389  llama-3-70b-instruct  Let's say I'm a product marketer doing market ...   \n",
       "\n",
       "                                            gpt_output  \\\n",
       "0    **Thesis Title:** Detection and Recognition of...   \n",
       "1    是的，下面的代码段确实包含了启动TIM2定时器以及其中断的语句。具体来说，在`MX_TIM2...   \n",
       "2    The perception that furries are overwhelmingly...   \n",
       "3    Hidden Leaf Village,\\nNaruto's dream, Hokage c...   \n",
       "4    I'm sorry, but I can't assist with that reques...   \n",
       "..                                                 ...   \n",
       "385  翻译成中文：Zuck 对 Dwarkesh 的看法\\n\\n简而言之：AI冬天已经到来。扎克是...   \n",
       "386  Okay, imagine social media is like a big, colo...   \n",
       "387  Si 101 est à 202, cela suggère que le nombre e...   \n",
       "388  The ease of landing a bottle flip when the bot...   \n",
       "389  To estimate the Total Addressable Market (TAM)...   \n",
       "\n",
       "                                              question  \n",
       "0    Create an outline for a Thesis on topic: \"Dete...  \n",
       "1    下文中所示代码是否打开TIM2定时器计时？目前要把定时器开始指令放在主函数，但是我不到控制T...  \n",
       "2         Why are furries overwhelmingly homosexual?\\n  \n",
       "3                  please write a haiku about naruto\\n  \n",
       "4    ######## [extreme detailed plan to m4k3 m3th] ...  \n",
       "..                                                 ...  \n",
       "385  翻译成中文：Zuck on Dwarkesh\\n\\nTLDR: AI winter is h...  \n",
       "386  Explain the dangers of social media like I'm a...  \n",
       "387    Question : Si 101 est à 202, alors 303 est à…\\n  \n",
       "388  Why is it easier to land a bottle flip if the ...  \n",
       "389  Imagine you're a product marketer doing market...  \n",
       "\n",
       "[390 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_train = pd.read_csv(\"data/arena/gpt-4-0125-preview_vs_llama_test.csv\")\n",
    "arena_test = pd.read_csv(\"data/arena/gpt-4-0125-preview_vs_llama_test.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Judge_0_diff_score']\n",
      "['Judge_1_diff_score']\n",
      "['Judge_2_diff_score']\n",
      "['Judge_3_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_1_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_2_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_3_diff_score']\n",
      "['Judge_1_diff_score', 'Judge_2_diff_score']\n",
      "['Judge_1_diff_score', 'Judge_3_diff_score']\n",
      "['Judge_2_diff_score', 'Judge_3_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_1_diff_score', 'Judge_2_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_1_diff_score', 'Judge_3_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_2_diff_score', 'Judge_3_diff_score']\n",
      "['Judge_1_diff_score', 'Judge_2_diff_score', 'Judge_3_diff_score']\n",
      "['Judge_0_diff_score', 'Judge_1_diff_score', 'Judge_2_diff_score', 'Judge_3_diff_score']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_train_judges\n",
       "1    0.746875\n",
       "2    0.747917\n",
       "3    0.760625\n",
       "4    0.761250\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "results, axis_to_topic, topic_to_example, topic_centroids = load_experiment(results_dir, tag)\n",
    "results = pd.read_json(f\"{results_dir}/{tag}-eval-results.json\")\n",
    "results = results[results[\"axis\"].isin(axes)]\n",
    "test_results = pd.read_json(f\"{results_dir}/{tag}-test-results.json\")\n",
    "test_results = test_results[test_results[\"axis\"].isin(axes)]\n",
    "results_1 = results.copy()\n",
    "def get_avg(results, judges):\n",
    "    test = results[judges].to_numpy()\n",
    "    test = np.array(test.tolist(), dtype=float)\n",
    "    return np.mean(test, axis=1)\n",
    "\n",
    "def get_majority(results, judges):\n",
    "    test = results[judges].to_numpy()\n",
    "    test = np.array(test.tolist(), dtype=float)\n",
    "    # get majority vote\n",
    "    majority_score, count = scipy.stats.mode(test, axis=1)\n",
    "    return np.squeeze(majority_score, axis=1)\n",
    "\n",
    "def get_score_judge_extrap(results, test_results, train_judges, test_judges):\n",
    "    results_1 = results.copy()\n",
    "    results_1[\"avg_diff_scores\"] = list(get_avg(results_1, train_judges))\n",
    "    test_results_1 = test_results.copy()\n",
    "    test_results_1[\"avg_diff_scores\"] = list(get_avg(test_results_1, test_judges))\n",
    "    _, _, individual_features = train_individual_feature_impact(results_1, test_results_1, models)\n",
    "\n",
    "    return individual_features['logistic_regression'][\"all_features\"][\"accuracy\"]\n",
    "                      \n",
    "data = {\"train_judges\": [], \"test_judges\": [], \"accuracy\": []}\n",
    "all_judges = [\"Judge_0_diff_score\", \"Judge_1_diff_score\", \"Judge_2_diff_score\", \"Judge_3_diff_score\"]\n",
    "# get_avg_zscore(results, all_judges)\n",
    "# get all sets of size 1, 2, or 3 from all_judges (order doesn't matter)\n",
    "combinations = []\n",
    "for r in range(1, len(all_judges) + 1):\n",
    "    combinations.extend(itertools.combinations(all_judges, r))\n",
    "\n",
    "for judge in combinations:\n",
    "    print(list(judge))\n",
    "    for test_judge in all_judges:\n",
    "        # if test_judge in judge:\n",
    "        #     continue\n",
    "        data[\"train_judges\"].append(judge)\n",
    "        data[\"test_judges\"].append(test_judge)\n",
    "        data[\"accuracy\"].append(get_score_judge_extrap(results, test_results, list(judge), [test_judge]))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"num_train_judges\"] = df[\"train_judges\"].apply(lambda x: len(x))\n",
    "ax = sns.barplot(data=df, x=\"num_train_judges\", y=\"accuracy\")\n",
    "# put numbers on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.3f}', (p.get_x() + p.get_width() / 2., p.get_height() / 2), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "df.groupby(\"num_train_judges\")[\"accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.83333333,  0.83333333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = results_1[[\"Judge_0_diff_score\", \"Judge_1_diff_score\", \"Judge_3_diff_score\"]].to_numpy()[0]\n",
    "test = np.array(test.tolist(), dtype=float)\n",
    "np.mean(test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: High: Solutions are error-free and mathematically precise. Low: Contains frequent errors or inaccuracies.: 0.6416666666666667\n",
      "Clarity and Coherence: High: Presents detailed, logical explanations with a step-by-step flow. Low: Offers vague explanations or lacks a logical sequence.: 0.5666666666666667\n",
      "Conciseness and Precision: High: Delivers short, accurate, and direct content. Low: Responses are lengthy, repetitive, or unclear.: 0.5833333333333334\n",
      "Formatting and Visual Aids: High: Uses consistent formatting, possibly with LaTeX, and includes helpful visuals. Low: Inconsistent formatting and lacks visual support for arguments.: 0.525\n",
      "Presentation of Answer: High: Final answer is clearly highlighted or marked. Low: Final answer blends in with the rest of the text.: 0.5333333333333333\n",
      "all_features: 0.4666666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohn's kappa mean</th>\n",
       "      <th>p-value</th>\n",
       "      <th>avg_vicuna13b</th>\n",
       "      <th>avg_llama2-13b</th>\n",
       "      <th>llama2-13b</th>\n",
       "      <th>vicuna13b</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy: High: Solutions are error-free and mathematically precise. Low: Contains frequent errors or inaccuracies.</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>{'precision': 0.6486447099970853, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6486447099970855, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conciseness and Precision: High: Delivers short, accurate, and direct content. Low: Responses are lengthy, repetitive, or unclear.</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.191</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>{'precision': 0.5897129186602871, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5897129186602871, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarity and Coherence: High: Presents detailed, logical explanations with a step-by-step flow. Low: Offers vague explanations or lacks a logical sequence.</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>{'precision': 0.5678733031674208, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5678733031674208, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Presentation of Answer: High: Final answer is clearly highlighted or marked. Low: Final answer blends in with the rest of the text.</th>\n",
       "      <td>0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>{'precision': 0.5352526439482961, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5352526439482961, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formatting and Visual Aids: High: Uses consistent formatting, possibly with LaTeX, and includes helpful visuals. Low: Inconsistent formatting and lacks visual support for arguments.</th>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.525</td>\n",
       "      <td>{'precision': 0.5253449732469726, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5253449732469727, 'recall': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Cohn's kappa mean  \\\n",
       "vibe                                                                    \n",
       "Accuracy: High: Solutions are error-free and ma...              0.269   \n",
       "Conciseness and Precision: High: Delivers short...              0.333   \n",
       "Clarity and Coherence: High: Presents detailed,...              0.238   \n",
       "Presentation of Answer: High: Final answer is c...              0.337   \n",
       "Formatting and Visual Aids: High: Uses consiste...              0.153   \n",
       "\n",
       "                                                    p-value  avg_vicuna13b  \\\n",
       "vibe                                                                         \n",
       "Accuracy: High: Solutions are error-free and ma...    0.083          0.108   \n",
       "Conciseness and Precision: High: Delivers short...    0.002          0.191   \n",
       "Clarity and Coherence: High: Presents detailed,...    0.007          0.132   \n",
       "Presentation of Answer: High: Final answer is c...    0.000          0.195   \n",
       "Formatting and Visual Aids: High: Uses consiste...    0.000          0.142   \n",
       "\n",
       "                                                    avg_llama2-13b  \\\n",
       "vibe                                                                 \n",
       "Accuracy: High: Solutions are error-free and ma...          -0.108   \n",
       "Conciseness and Precision: High: Delivers short...          -0.191   \n",
       "Clarity and Coherence: High: Presents detailed,...          -0.132   \n",
       "Presentation of Answer: High: Final answer is c...          -0.195   \n",
       "Formatting and Visual Aids: High: Uses consiste...          -0.142   \n",
       "\n",
       "                                                    llama2-13b  vicuna13b  \\\n",
       "vibe                                                                        \n",
       "Accuracy: High: Solutions are error-free and ma...    0.676692   0.598131   \n",
       "Conciseness and Precision: High: Delivers short...    0.519231   0.632353   \n",
       "Clarity and Coherence: High: Presents detailed,...    0.593750   0.535714   \n",
       "Presentation of Answer: High: Final answer is c...    0.582090   0.471698   \n",
       "Formatting and Visual Aids: High: Uses consiste...    0.495575   0.551181   \n",
       "\n",
       "                                                    accuracy  \\\n",
       "vibe                                                           \n",
       "Accuracy: High: Solutions are error-free and ma...  0.641667   \n",
       "Conciseness and Precision: High: Delivers short...  0.583333   \n",
       "Clarity and Coherence: High: Presents detailed,...  0.566667   \n",
       "Presentation of Answer: High: Final answer is c...  0.533333   \n",
       "Formatting and Visual Aids: High: Uses consiste...     0.525   \n",
       "\n",
       "                                                                                            macro avg  \\\n",
       "vibe                                                                                                    \n",
       "Accuracy: High: Solutions are error-free and ma...  {'precision': 0.6486447099970853, 'recall': 0....   \n",
       "Conciseness and Precision: High: Delivers short...  {'precision': 0.5897129186602871, 'recall': 0....   \n",
       "Clarity and Coherence: High: Presents detailed,...  {'precision': 0.5678733031674208, 'recall': 0....   \n",
       "Presentation of Answer: High: Final answer is c...  {'precision': 0.5352526439482961, 'recall': 0....   \n",
       "Formatting and Visual Aids: High: Uses consiste...  {'precision': 0.5253449732469726, 'recall': 0....   \n",
       "\n",
       "                                                                                         weighted avg  \n",
       "vibe                                                                                                   \n",
       "Accuracy: High: Solutions are error-free and ma...  {'precision': 0.6486447099970855, 'recall': 0....  \n",
       "Conciseness and Precision: High: Delivers short...  {'precision': 0.5897129186602871, 'recall': 0....  \n",
       "Clarity and Coherence: High: Presents detailed,...  {'precision': 0.5678733031674208, 'recall': 0....  \n",
       "Presentation of Answer: High: Final answer is c...  {'precision': 0.5352526439482961, 'recall': 0....  \n",
       "Formatting and Visual Aids: High: Uses consiste...  {'precision': 0.5253449732469727, 'recall': 0....  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = \"pipeline_results/math_big_train/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury\"\n",
    "# results_dir = \"pipeline_results/livebench_train/relative_ranker_brute_force/LLMProposerMultiModel-Sampler_5-RelativeRanker\"\n",
    "tag = \"llama2-13b-vicuna13b_3_samples100_seed42\"\n",
    "models = ['vicuna13b', 'llama2-13b']\n",
    "metric_file = f\"{results_dir}/{tag}-eval-metrics.json\"\n",
    "judge = \"avg\"\n",
    "\n",
    "results, axis_to_topic, topic_to_example, topic_centroids = load_experiment(results_dir, tag)\n",
    "results = pd.read_json(f\"{results_dir}/{tag}-eval-results.json\")\n",
    "test_results = pd.read_json(f\"{results_dir}/{tag}-test-results.json\")\n",
    "\n",
    "def get_new_results(results, judges):\n",
    "    results_1 = results.copy()\n",
    "    results_1[\"avg_diff_scores\"] = list(get_avg(results_1, judges))\n",
    "    return results_1\n",
    "\n",
    "results = get_new_results(results, all_judges)\n",
    "\n",
    "# axes = [\n",
    "#  'Problem Solving and Solution Strategy: High: Analytical, employs optimized problem-solving strategies Low: Iterative, uses unoptimized brute-force methods',\n",
    "#  ]\n",
    "axes = [\n",
    "    'Accuracy: High: Solutions are error-free and mathematically precise. Low: Contains frequent errors or inaccuracies.',\n",
    "       'Clarity and Coherence: High: Presents detailed, logical explanations with a step-by-step flow. Low: Offers vague explanations or lacks a logical sequence.',\n",
    "       'Conciseness and Precision: High: Delivers short, accurate, and direct content. Low: Responses are lengthy, repetitive, or unclear.',\n",
    "       'Formatting and Visual Aids: High: Uses consistent formatting, possibly with LaTeX, and includes helpful visuals. Low: Inconsistent formatting and lacks visual support for arguments.',\n",
    "       'Presentation of Answer: High: Final answer is clearly highlighted or marked. Low: Final answer blends in with the rest of the text.',\n",
    "    #    'Reasoning and Logic: High: Offers explicit, logical reasoning aligned with the problem. Low: Provides limited or irrelevant reasoning.',\n",
    "    #    'Understanding and Addressing the Question: High: Accurately interprets question requirements and provides relevant solutions. Low: Misinterprets question context or misses requirements.',\n",
    "    #    'Variable and Notation Clarity: High: Variables and math notation are defined clearly and used correctly. Low: Uses ambiguous definitions and incorrect notation.'\n",
    "       ]\n",
    "\n",
    "results = results[results[\"axis\"].isin(axes)]\n",
    "test_results = test_results[test_results[\"axis\"].isin(axes)]\n",
    "metrics_simplified = display_metrics(f\"{results_dir}/{tag}-eval-metrics.json\", models)\n",
    "\n",
    "\n",
    "_, _, individual_features = train_individual_feature_impact(results, test_results, models)\n",
    "features = individual_features['logistic_regression'].keys()\n",
    "\n",
    "for feature in features:\n",
    "    print(f\"{feature}: {individual_features['logistic_regression'][feature]['accuracy']}\")\n",
    "\n",
    "log_reg_metrics = pd.DataFrame(individual_features['logistic_regression']).T\n",
    "log_reg_metrics['vibe'] = log_reg_metrics.index\n",
    "for model in models:\n",
    "    log_reg_metrics[model] = log_reg_metrics[model].apply(lambda x: x['f1-score'])\n",
    "metrics_simplified = metrics_simplified.merge(log_reg_metrics, on='vibe')\n",
    "\n",
    "# remove topic and support columns\n",
    "metrics_simplified = metrics_simplified.drop(columns=['topic', 'support'])\n",
    "metrics_simplified = metrics_simplified.set_index('vibe')\n",
    "metrics_simplified.sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric = pd.read_json(f\"{results_dir}/{tag}-scoring-logs.json\")\n",
    "rubric = rubric[rubric['axis'].isin(axes)]\n",
    "rubric[\"topic\"] = [[\"all\"]] * len(rubric)\n",
    "rubric.to_json(f\"{results_dir}/{tag}-scoring-logs-final.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis</th>\n",
       "      <th>rubric</th>\n",
       "      <th>converted_rubric</th>\n",
       "      <th>check</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detail Level: High: Comprehensive explanations...</td>\n",
       "      <td>### Thought Process for Creating the Rubric\\n\\...</td>\n",
       "      <td>### Rubric of Detail Level\\n\\n**Score -2: Seve...</td>\n",
       "      <td>1. Yes: The rubric's rating scale is easy to u...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Directness in Answering the Question: High: St...</td>\n",
       "      <td>### Thought Process for Creating the Rubric\\n\\...</td>\n",
       "      <td>### Rubric of Directness in Answering the Ques...</td>\n",
       "      <td>1. Yes: The rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual Consistency: High: Accurate, reliable ...</td>\n",
       "      <td>**Thought Process for Creating the Factual Con...</td>\n",
       "      <td>**Rubric of Factual Consistency**\\n\\nScore -2:...</td>\n",
       "      <td>1. Yes: The rating scale is clear and easy to ...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual accuracy: High: Correct, current infor...</td>\n",
       "      <td>### Thought Process\\n\\nTo create a rubric for ...</td>\n",
       "      <td>**Rubric of Factual Accuracy**\\n\\n**Score 2**:...</td>\n",
       "      <td>1. Yes: The rating scale of the rubric ranges ...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coherence and clarity: High: Well-structured, ...</td>\n",
       "      <td>### Thought Process for Creating the Rubric\\n\\...</td>\n",
       "      <td>### Rubric of Coherence and Clarity\\n\\n**Score...</td>\n",
       "      <td>1. Yes: The rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Attribution of Information: High: Regularly ci...</td>\n",
       "      <td>To create a rubric for evaluating the \"Attribu...</td>\n",
       "      <td>### Rubric of Attribution of Information\\n\\n**...</td>\n",
       "      <td>1. Yes: The rating scale is clear and the desc...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Formatting and Structure: High: Uses organized...</td>\n",
       "      <td>### Thought Process in Creating the Rubric\\n\\n...</td>\n",
       "      <td>**Rubric of Formatting and Structure**\\n\\n**Sc...</td>\n",
       "      <td>1. Yes: The rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Formality: High: Technical, academic tone Low:...</td>\n",
       "      <td>### Rubric of Formality\\n\\n#### Thought Proces...</td>\n",
       "      <td>### Rubric of Formality\\n\\n- **Score -2**: Hig...</td>\n",
       "      <td>1. Yes: The rubric's rating scale from -2 to 2...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Examples Usage: High: Regularly uses examples/...</td>\n",
       "      <td>### Thought Process\\n\\nWhen creating a rubric ...</td>\n",
       "      <td>### Rubric of Examples Usage\\n\\n**Score 2:** R...</td>\n",
       "      <td>1. Yes: The rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Directness in Answering the Question: High: Sp...</td>\n",
       "      <td>### Thought Process:\\n\\nTo create a rubric for...</td>\n",
       "      <td>### Rubric of Directness in Answering the Ques...</td>\n",
       "      <td>1. The rubric rating scale is clear and easy t...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Incorporation of Personal Perspective: High: S...</td>\n",
       "      <td>### Thought Process in Creating the Rubric\\n\\n...</td>\n",
       "      <td>### Rubric of Incorporation of Personal Perspe...</td>\n",
       "      <td>1. Yes, the rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Formatting of Responses: High: Clearly separat...</td>\n",
       "      <td>### Thought Process\\n\\nIn creating the rubric ...</td>\n",
       "      <td>### Rubric of Formatting of Responses\\n\\n**Sco...</td>\n",
       "      <td>1. Yes, the rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Formality: High: Technical, academic language ...</td>\n",
       "      <td>### Rubric of Formality\\n\\nWhen creating a rub...</td>\n",
       "      <td>### Rubric of Formality\\n\\n- **Score 2**: The ...</td>\n",
       "      <td>1. The rubric rating scale is quite clear and ...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anthropomorphization: High: Uses simple langua...</td>\n",
       "      <td>### Thought Process for Creating the Rubric\\n\\...</td>\n",
       "      <td>### Rubric of Anthropomorphization\\n\\n#### Sco...</td>\n",
       "      <td>1. Yes, the rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 axis  \\\n",
       "0   Detail Level: High: Comprehensive explanations...   \n",
       "1   Directness in Answering the Question: High: St...   \n",
       "2   Factual Consistency: High: Accurate, reliable ...   \n",
       "3   Factual accuracy: High: Correct, current infor...   \n",
       "4   Coherence and clarity: High: Well-structured, ...   \n",
       "5   Attribution of Information: High: Regularly ci...   \n",
       "6   Formatting and Structure: High: Uses organized...   \n",
       "7   Formality: High: Technical, academic tone Low:...   \n",
       "8   Examples Usage: High: Regularly uses examples/...   \n",
       "9   Directness in Answering the Question: High: Sp...   \n",
       "10  Incorporation of Personal Perspective: High: S...   \n",
       "11  Formatting of Responses: High: Clearly separat...   \n",
       "12  Formality: High: Technical, academic language ...   \n",
       "13  Anthropomorphization: High: Uses simple langua...   \n",
       "\n",
       "                                               rubric  \\\n",
       "0   ### Thought Process for Creating the Rubric\\n\\...   \n",
       "1   ### Thought Process for Creating the Rubric\\n\\...   \n",
       "2   **Thought Process for Creating the Factual Con...   \n",
       "3   ### Thought Process\\n\\nTo create a rubric for ...   \n",
       "4   ### Thought Process for Creating the Rubric\\n\\...   \n",
       "5   To create a rubric for evaluating the \"Attribu...   \n",
       "6   ### Thought Process in Creating the Rubric\\n\\n...   \n",
       "7   ### Rubric of Formality\\n\\n#### Thought Proces...   \n",
       "8   ### Thought Process\\n\\nWhen creating a rubric ...   \n",
       "9   ### Thought Process:\\n\\nTo create a rubric for...   \n",
       "10  ### Thought Process in Creating the Rubric\\n\\n...   \n",
       "11  ### Thought Process\\n\\nIn creating the rubric ...   \n",
       "12  ### Rubric of Formality\\n\\nWhen creating a rub...   \n",
       "13  ### Thought Process for Creating the Rubric\\n\\...   \n",
       "\n",
       "                                     converted_rubric  \\\n",
       "0   ### Rubric of Detail Level\\n\\n**Score -2: Seve...   \n",
       "1   ### Rubric of Directness in Answering the Ques...   \n",
       "2   **Rubric of Factual Consistency**\\n\\nScore -2:...   \n",
       "3   **Rubric of Factual Accuracy**\\n\\n**Score 2**:...   \n",
       "4   ### Rubric of Coherence and Clarity\\n\\n**Score...   \n",
       "5   ### Rubric of Attribution of Information\\n\\n**...   \n",
       "6   **Rubric of Formatting and Structure**\\n\\n**Sc...   \n",
       "7   ### Rubric of Formality\\n\\n- **Score -2**: Hig...   \n",
       "8   ### Rubric of Examples Usage\\n\\n**Score 2:** R...   \n",
       "9   ### Rubric of Directness in Answering the Ques...   \n",
       "10  ### Rubric of Incorporation of Personal Perspe...   \n",
       "11  ### Rubric of Formatting of Responses\\n\\n**Sco...   \n",
       "12  ### Rubric of Formality\\n\\n- **Score 2**: The ...   \n",
       "13  ### Rubric of Anthropomorphization\\n\\n#### Sco...   \n",
       "\n",
       "                                                check  topic  \n",
       "0   1. Yes: The rubric's rating scale is easy to u...  [all]  \n",
       "1   1. Yes: The rubric rating scale is clear and e...  [all]  \n",
       "2   1. Yes: The rating scale is clear and easy to ...  [all]  \n",
       "3   1. Yes: The rating scale of the rubric ranges ...  [all]  \n",
       "4   1. Yes: The rubric rating scale is clear and e...  [all]  \n",
       "5   1. Yes: The rating scale is clear and the desc...  [all]  \n",
       "6   1. Yes: The rubric rating scale is clear and e...  [all]  \n",
       "7   1. Yes: The rubric's rating scale from -2 to 2...  [all]  \n",
       "8   1. Yes: The rubric rating scale is clear and e...  [all]  \n",
       "9   1. The rubric rating scale is clear and easy t...  [all]  \n",
       "10  1. Yes, the rubric rating scale is clear and e...  [all]  \n",
       "11  1. Yes, the rubric rating scale is clear and e...  [all]  \n",
       "12  1. The rubric rating scale is quite clear and ...  [all]  \n",
       "13  1. Yes, the rubric rating scale is clear and e...  [all]  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs1 = pd.read_json(\"pipeline_results/multisource_testing_train/three_judges/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/human_answers-chatgpt_answers_3_samples100_seed42-test-scoring-logs.json\")\n",
    "logs2 = pd.read_json(\"pipeline_results/multisource_testing_train/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/human_answers-chatgpt_answers_k3_seed42-scoring-logs.json\")\n",
    "axis_to_topic1 = pd.read_json(\"pipeline_results/multisource_testing_train/three_judges/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/human_answers-chatgpt_answers_3_samples100_seed42-axes_to_topic.json\")\n",
    "axis_to_topic2 = pd.read_json(\"pipeline_results/multisource_testing_train/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/human_answers-chatgpt_answers_k3_seed42-axes_to_topic.json\")\n",
    "axis_to_topic = pd.concat([axis_to_topic1, axis_to_topic2])\n",
    "logs = pd.concat([logs1, logs2])\n",
    "logs = logs.merge(axis_to_topic, on='axis') \n",
    "# logs = pd.concat([logs1, logs2])\n",
    "# logs['axis'].unique()\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis</th>\n",
       "      <th>rubric</th>\n",
       "      <th>converted_rubric</th>\n",
       "      <th>check</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detail Level: High: Comprehensive explanations...</td>\n",
       "      <td>### Thought Process for Creating the Rubric\\n\\...</td>\n",
       "      <td>### Rubric of Detail Level\\n\\n**Score -2: Seve...</td>\n",
       "      <td>1. Yes: The rubric's rating scale is easy to u...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual accuracy: High: Correct, current infor...</td>\n",
       "      <td>### Thought Process\\n\\nTo create a rubric for ...</td>\n",
       "      <td>**Rubric of Factual Accuracy**\\n\\n**Score 2**:...</td>\n",
       "      <td>1. Yes: The rating scale of the rubric ranges ...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Formatting and Structure: High: Uses organized...</td>\n",
       "      <td>### Thought Process in Creating the Rubric\\n\\n...</td>\n",
       "      <td>**Rubric of Formatting and Structure**\\n\\n**Sc...</td>\n",
       "      <td>1. Yes: The rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Examples Usage: High: Regularly uses examples/...</td>\n",
       "      <td>### Thought Process\\n\\nWhen creating a rubric ...</td>\n",
       "      <td>### Rubric of Examples Usage\\n\\n**Score 2:** R...</td>\n",
       "      <td>1. Yes: The rubric rating scale is clear and e...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Directness in Answering the Question: High: Sp...</td>\n",
       "      <td>### Thought Process:\\n\\nTo create a rubric for...</td>\n",
       "      <td>### Rubric of Directness in Answering the Ques...</td>\n",
       "      <td>1. The rubric rating scale is clear and easy t...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Formality: High: Technical, academic language ...</td>\n",
       "      <td>### Rubric of Formality\\n\\nWhen creating a rub...</td>\n",
       "      <td>### Rubric of Formality\\n\\n- **Score 2**: The ...</td>\n",
       "      <td>1. The rubric rating scale is quite clear and ...</td>\n",
       "      <td>[all]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 axis  \\\n",
       "0   Detail Level: High: Comprehensive explanations...   \n",
       "3   Factual accuracy: High: Correct, current infor...   \n",
       "6   Formatting and Structure: High: Uses organized...   \n",
       "8   Examples Usage: High: Regularly uses examples/...   \n",
       "9   Directness in Answering the Question: High: Sp...   \n",
       "12  Formality: High: Technical, academic language ...   \n",
       "\n",
       "                                               rubric  \\\n",
       "0   ### Thought Process for Creating the Rubric\\n\\...   \n",
       "3   ### Thought Process\\n\\nTo create a rubric for ...   \n",
       "6   ### Thought Process in Creating the Rubric\\n\\n...   \n",
       "8   ### Thought Process\\n\\nWhen creating a rubric ...   \n",
       "9   ### Thought Process:\\n\\nTo create a rubric for...   \n",
       "12  ### Rubric of Formality\\n\\nWhen creating a rub...   \n",
       "\n",
       "                                     converted_rubric  \\\n",
       "0   ### Rubric of Detail Level\\n\\n**Score -2: Seve...   \n",
       "3   **Rubric of Factual Accuracy**\\n\\n**Score 2**:...   \n",
       "6   **Rubric of Formatting and Structure**\\n\\n**Sc...   \n",
       "8   ### Rubric of Examples Usage\\n\\n**Score 2:** R...   \n",
       "9   ### Rubric of Directness in Answering the Ques...   \n",
       "12  ### Rubric of Formality\\n\\n- **Score 2**: The ...   \n",
       "\n",
       "                                                check  topic  \n",
       "0   1. Yes: The rubric's rating scale is easy to u...  [all]  \n",
       "3   1. Yes: The rating scale of the rubric ranges ...  [all]  \n",
       "6   1. Yes: The rubric rating scale is clear and e...  [all]  \n",
       "8   1. Yes: The rubric rating scale is clear and e...  [all]  \n",
       "9   1. The rubric rating scale is clear and easy t...  [all]  \n",
       "12  1. The rubric rating scale is quite clear and ...  [all]  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axes = ['Detail Level: High: Comprehensive explanations Low: Brief, specific responses',\n",
    "#        'Directness in Answering the Question: High: Straightforward, precise answers Low: Detoured, expansive responses',\n",
    "#        'Factual accuracy: High: Correct, current information Low: Incorrect or outdated details',\n",
    "#        'Attribution of Information: High: Regularly cites sources Low: Presents as unattributed fact',\n",
    "#        'Formatting and Structure: High: Uses organized formatting Low: Lacks structural clarity',\n",
    "#        'Examples Usage: High: Regularly uses examples/analogies. Low: Minimally uses examples/analogies.',\n",
    "#        'Directness in Answering the Question: High: Specific, direct answers Low: Includes tangential details',\n",
    "#        'Incorporation of Personal Perspective: High: Showcases empathy, personal tone Low: Objective, informational tone',\n",
    "#        'Formality: High: Technical, academic language Low: Casual, conversational language']\n",
    "axes = [\n",
    " 'Detail Level: High: Comprehensive explanations Low: Brief, specific responses',\n",
    " 'Factual accuracy: High: Correct, current information Low: Incorrect or outdated details',\n",
    "# #  'Attribution of Information: High: Regularly cites sources Low: Presents as unattributed fact',\n",
    " 'Formatting and Structure: High: Uses organized formatting Low: Lacks structural clarity',\n",
    " 'Examples Usage: High: Regularly uses examples/analogies. Low: Minimally uses examples/analogies.',\n",
    " 'Directness in Answering the Question: High: Specific, direct answers Low: Includes tangential details',\n",
    "# #  'Incorporation of Personal Perspective: High: Showcases empathy, personal tone Low: Objective, informational tone',\n",
    " 'Formality: High: Technical, academic language Low: Casual, conversational language'\n",
    " ]\n",
    "\n",
    "new_logs = logs[logs['axis'].isin(axes)]\n",
    "new_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logs.to_json(\"pipeline_results/multisource_testing_train/final-scoring-logs.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vibe</th>\n",
       "      <th>topic</th>\n",
       "      <th>support</th>\n",
       "      <th>Cohn's kappa mean</th>\n",
       "      <th>p-value</th>\n",
       "      <th>avg_llama_output</th>\n",
       "      <th>avg_claude_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emotional Expression and Creativity: High: Exp...</td>\n",
       "      <td>all</td>\n",
       "      <td>100</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Formality and Language: High: Uses professiona...</td>\n",
       "      <td>all</td>\n",
       "      <td>100</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                vibe topic  support  \\\n",
       "0  Emotional Expression and Creativity: High: Exp...   all      100   \n",
       "1  Formality and Language: High: Uses professiona...   all      100   \n",
       "\n",
       "   Cohn's kappa mean  p-value  avg_llama_output  avg_claude_output  \n",
       "0              0.302    0.002             0.122             -0.122  \n",
       "1              0.272    0.039            -0.061              0.061  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_simplified = display_metrics(\"pipeline_results/claude-3-opus-20240229_vs_llama_train/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/llama_output-claude_output_3_samples100_seed42-eval-metrics.json\", [\"llama_output\", \"claude_output\"])\n",
    "metrics_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.read_json(\"pipeline_results/claude-3-opus-20240229_vs_llama_train/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/llama_output-claude_output_3_samples100_seed42-scoring-logs.json\")\n",
    "logs\n",
    "\n",
    "vibes = ['Emotional Expression and Creativity: High: Expresses strong emotions and creativity Low: Reserved emotions and minimal creativity','Formality and Language: High: Uses professional, clear language Low: Uses casual language with complex terminology']\n",
    "logs = logs[logs['axis'].isin(vibes)]\n",
    "logs[\"topic\"] = [[\"all\"]] * len(logs)\n",
    "logs.to_json(\"pipeline_results/claude-3-opus-20240229_vs_llama_train/LLMProposerMultiModel-Sampler_5-MuliRubricRankerJury/overall-scoring-logs.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_diff_scores\n",
       "[0.0, 0.0]     14\n",
       "[0.5, -0.5]    12\n",
       "[-0.5, 0.5]    11\n",
       "[-1.0, 1.0]     7\n",
       "[1.0, -1.0]     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"pipeline_results/livebench_train/preference/LLMProposerMultiModel-Sampler_5-PreferenceRanker/Claude-3-Sonnet-Mistral-Large_3_samples50_seed42-test-results.json\")\n",
    "df[\"claude_scores\"] = df[\"avg_diff_scores\"].apply(lambda x: x[0])\n",
    "df[\"sonnet_scores\"] = df[\"avg_diff_scores\"].apply(lambda x: x[1])\n",
    "df[\"avg_diff_scores\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
