project: VibeCheck-HumanVSGpt
wandb: False # Set to True to log to Weights and Biases
num_samples: False
dummy_eval: False
oz: False
group_column: False
proposer: LLMProposerMultiModel
reducer: AxisReducer
sampler: ClusterSampler
test: False
save_dir: pipeline_results
data_path: data/gpt_vs_human/multisource_testing.csv
num_topic_clusters: 5
proposer_only: False
k: 3
batch_size: 50
num_eval: 3
embedding_model: text-embedding-3-small
seed: 42
cluster_method: hierarchical
proposer_batch_size: 10
ranker: MuliRubricRankerJury
heldout_percentage: 0.5
judges: [gpt-3.5-turbo, claude-3-haiku-20240307, llama-3-8b]
models: [human_answers, chatgpt_answers]
eval_only: False
axes: False
# axes: [
#     "Formality: High = Formal language, technical terms, polite expressions; Low = Casual, slang, informal expressions",
#     "Complexity: High = Complex sentence structures, advanced vocabulary; Low = Simple language, basic vocabulary",
#     "Structure: High = Organized with headings, bullet points; Low = Free-form prose, stream of consciousness",
#     "Objectivity: High = Fact-based, neutral tone; Low = Subjective, personal opinions, emotionally charged",
#     "Creativity: High = Novel ideas, unique expressions, imaginative; Low = Conventional ideas, clich√©d expressions",
#     "Level of Detail: High = Specific and detailed information, accurate facts; Low = Vauge or high-level information",
#     "Tone: High = Distinct emotional quality, human-like expressiveness; Low = Neutral, no distinct emotional quality",
#     "Engagement & Influence: High = Engages and persuades with questions, calls to action; Low = Non-engaging, purely informational",
#     "Adherence to Prompt: High = Closely follows the prompt; Low = Deviates from or ignores the prompt",
# ]